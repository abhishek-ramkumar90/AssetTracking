{"ast":null,"code":"'use strict';\n\nvar USE_TYPEDARRAY = typeof Uint8Array !== 'undefined' && typeof Uint16Array !== 'undefined' && typeof Uint32Array !== 'undefined';\n\nvar pako = require(\"pako\");\n\nvar utils = require(\"./utils\");\n\nvar GenericWorker = require(\"./stream/GenericWorker\");\n\nvar ARRAY_TYPE = USE_TYPEDARRAY ? \"uint8array\" : \"array\";\nexports.magic = \"\\x08\\x00\";\n/**\n * Create a worker that uses pako to inflate/deflate.\n * @constructor\n * @param {String} action the name of the pako function to call : either \"Deflate\" or \"Inflate\".\n * @param {Object} options the options to use when (de)compressing.\n */\n\nfunction FlateWorker(action, options) {\n  GenericWorker.call(this, \"FlateWorker/\" + action);\n  this._pako = new pako[action]({\n    raw: true,\n    level: options.level || -1 // default compression\n\n  }); // the `meta` object from the last chunk received\n  // this allow this worker to pass around metadata\n\n  this.meta = {};\n  var self = this;\n\n  this._pako.onData = function (data) {\n    self.push({\n      data: data,\n      meta: self.meta\n    });\n  };\n}\n\nutils.inherits(FlateWorker, GenericWorker);\n/**\n * @see GenericWorker.processChunk\n */\n\nFlateWorker.prototype.processChunk = function (chunk) {\n  this.meta = chunk.meta;\n\n  this._pako.push(utils.transformTo(ARRAY_TYPE, chunk.data), false);\n};\n/**\n * @see GenericWorker.flush\n */\n\n\nFlateWorker.prototype.flush = function () {\n  GenericWorker.prototype.flush.call(this);\n\n  this._pako.push([], true);\n};\n/**\n * @see GenericWorker.cleanUp\n */\n\n\nFlateWorker.prototype.cleanUp = function () {\n  GenericWorker.prototype.cleanUp.call(this);\n  this._pako = null;\n};\n\nexports.compressWorker = function (compressionOptions) {\n  return new FlateWorker(\"Deflate\", compressionOptions);\n};\n\nexports.uncompressWorker = function () {\n  return new FlateWorker(\"Inflate\", {});\n};","map":null,"metadata":{},"sourceType":"script"}